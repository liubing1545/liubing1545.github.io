<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bad Seeds</title>
  
  <subtitle>thug life</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://liubing.com/"/>
  <updated>2021-07-16T02:27:02.085Z</updated>
  <id>http://liubing.com/</id>
  
  <author>
    <name>liubing</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>anaconda安装tensorflow</title>
    <link href="http://liubing.com/2021/07/02/%E6%B5%8B%E8%AF%95%E4%B8%80%E4%B8%8B/"/>
    <id>http://liubing.com/2021/07/02/%E6%B5%8B%E8%AF%95%E4%B8%80%E4%B8%8B/</id>
    <published>2021-07-02T03:30:25.000Z</published>
    <updated>2021-07-16T02:27:02.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="下载anaconda"><a href="#下载anaconda" class="headerlink" title="下载anaconda"></a>下载anaconda</h2><p>测试一下</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;下载anaconda&quot;&gt;&lt;a href=&quot;#下载anaconda&quot; class=&quot;headerlink&quot; title=&quot;下载anaconda&quot;&gt;&lt;/a&gt;下载anaconda&lt;/h2&gt;&lt;p&gt;测试一下&lt;/p&gt;

      
    
    </summary>
    
    
    
      <category term="anaconda" scheme="http://liubing.com/tags/anaconda/"/>
    
      <category term="conda" scheme="http://liubing.com/tags/conda/"/>
    
      <category term="tensorflow" scheme="http://liubing.com/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>MultiHash和Base58</title>
    <link href="http://liubing.com/2020/05/23/MultiHash%E5%92%8CBase58/"/>
    <id>http://liubing.com/2020/05/23/MultiHash%E5%92%8CBase58/</id>
    <published>2020-05-23T03:42:10.000Z</published>
    <updated>2021-07-16T02:27:02.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MultiHash和Base58"><a href="#MultiHash和Base58" class="headerlink" title="MultiHash和Base58"></a>MultiHash和Base58</h2><h3 id="MultiHash"><a href="#MultiHash" class="headerlink" title="MultiHash"></a>MultiHash</h3><p>目前IPFS使用SHA2-256的加密方式，目前来说比较安全，但随着科技发展，说不定哪天就会被破解。因此IPFS在制定协议时，采用了MultiHash这种方式，可扩展支持多种HASH算法。如果未来改用了别的算法，用的仍然是MultiHash，也就保持了加密方式的持续性。</p><h4 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h4><ul><li>HASH算法编码</li><li>HASH值长度（字节数）</li><li>HASH值</li></ul><p>SHA2-256的编码为0x12，其Hash摘要长度为32字节（十六进制为0x20）。</p><p>所以将 <strong>1220</strong> 添加到所有的Hash值前。</p><h3 id="Base58"><a href="#Base58" class="headerlink" title="Base58"></a>Base58</h3><p>Base64有一些缺点，就是某些字符容易混淆，比如<strong>O</strong>和<strong>0</strong>等。很容易将字符串认错，造成阅读上的障碍。Base58将Hash值压缩，并且剔除了干扰字符。</p><p>因此<strong>1220</strong>开头的Hash值都被编码成了<strong>Qm</strong>开头。</p><p>这就是ipfs add时，返回的CID都是Qm开头的原因。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;MultiHash和Base58&quot;&gt;&lt;a href=&quot;#MultiHash和Base58&quot; class=&quot;headerlink&quot; title=&quot;MultiHash和Base58&quot;&gt;&lt;/a&gt;MultiHash和Base58&lt;/h2&gt;&lt;h3 id=&quot;MultiHash
      
    
    </summary>
    
    
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
      <category term="MultiHash" scheme="http://liubing.com/tags/MultiHash/"/>
    
      <category term="Base58" scheme="http://liubing.com/tags/Base58/"/>
    
  </entry>
  
  <entry>
    <title>ServiceWorker尝试</title>
    <link href="http://liubing.com/2020/05/22/ServiceWorker%E5%B0%9D%E8%AF%95/"/>
    <id>http://liubing.com/2020/05/22/ServiceWorker%E5%B0%9D%E8%AF%95/</id>
    <published>2020-05-22T07:51:10.000Z</published>
    <updated>2021-07-16T02:27:02.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ServiceWorker尝试"><a href="#ServiceWorker尝试" class="headerlink" title="ServiceWorker尝试"></a>ServiceWorker尝试</h2><h3 id="node12-14-0下安装sqlite3-3-1-13失败"><a href="#node12-14-0下安装sqlite3-3-1-13失败" class="headerlink" title="node12.14.0下安装sqlite3@3.1.13失败"></a>node12.14.0下安装<a href="mailto:sqlite3@3.1.13">sqlite3@3.1.13</a>失败</h3><blockquote><p>download (403): <a href="https://mapbox-node-binary.s3.amazonaws.com/sqlite3/v3.1.13/node-v72-win3">https://mapbox-node-binary.s3.amazonaws.com/sqlite3/v3.1.13/node-v72-win3</a> 2-x64.tar.gz</p><p>binaries not found for <a href="mailto:sqlite3@3.1.13">sqlite3@3.1.13</a> and <a href="mailto:node@12.14.0">node@12.14.0</a> (node-v72 ABI) (falling back to source compile with node-gyp)</p></blockquote><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>安装nvm <a href="https://github.com/coreybutler/nvm-windows/releases">下载地址</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvm install 8.9.3</span><br><span class="line">nvm use 8.9.3</span><br></pre></td></tr></table></figure><p>配置nvm，如果需要proxy的话就配置proxy</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nvm proxy http://$proxy-url/</span><br><span class="line">nvm node_mirror https://npm.taobao.org/mirrors/node/</span><br><span class="line">nvm npm_mirror https://npm.taobao.org/mirrors/npm/</span><br></pre></td></tr></table></figure><p>再次安装即能成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;ServiceWorker尝试&quot;&gt;&lt;a href=&quot;#ServiceWorker尝试&quot; class=&quot;headerlink&quot; title=&quot;ServiceWorker尝试&quot;&gt;&lt;/a&gt;ServiceWorker尝试&lt;/h2&gt;&lt;h3 id=&quot;node12-14-0下安
      
    
    </summary>
    
    
    
      <category term="node" scheme="http://liubing.com/tags/node/"/>
    
      <category term="Service Worker" scheme="http://liubing.com/tags/Service-Worker/"/>
    
  </entry>
  
  <entry>
    <title>nvm降级node安装sqlite3</title>
    <link href="http://liubing.com/2020/05/22/nvm%E9%99%8D%E7%BA%A7node%E5%AE%89%E8%A3%85sqlite3/"/>
    <id>http://liubing.com/2020/05/22/nvm%E9%99%8D%E7%BA%A7node%E5%AE%89%E8%A3%85sqlite3/</id>
    <published>2020-05-22T07:51:10.000Z</published>
    <updated>2021-07-16T02:27:02.082Z</updated>
    
    <content type="html"><![CDATA[<h2 id="nvm降级node安装sqlite3"><a href="#nvm降级node安装sqlite3" class="headerlink" title="nvm降级node安装sqlite3"></a>nvm降级node安装sqlite3</h2><h3 id="node12-14-0下安装sqlite3-3-1-13失败"><a href="#node12-14-0下安装sqlite3-3-1-13失败" class="headerlink" title="node12.14.0下安装sqlite3@3.1.13失败"></a>node12.14.0下安装<a href="mailto:sqlite3@3.1.13">sqlite3@3.1.13</a>失败</h3><blockquote><p>download (403): <a href="https://mapbox-node-binary.s3.amazonaws.com/sqlite3/v3.1.13/node-v72-win3">https://mapbox-node-binary.s3.amazonaws.com/sqlite3/v3.1.13/node-v72-win3</a> 2-x64.tar.gz</p><p>binaries not found for <a href="mailto:sqlite3@3.1.13">sqlite3@3.1.13</a> and <a href="mailto:node@12.14.0">node@12.14.0</a> (node-v72 ABI) (falling back to source compile with node-gyp)</p></blockquote><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>安装nvm <a href="https://github.com/coreybutler/nvm-windows/releases">下载地址</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvm install 8.9.3</span><br><span class="line">nvm use 8.9.3</span><br></pre></td></tr></table></figure><p>配置nvm，如果需要proxy的话就配置proxy</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nvm proxy http://$proxy-url/</span><br><span class="line">nvm node_mirror https://npm.taobao.org/mirrors/node/</span><br><span class="line">nvm npm_mirror https://npm.taobao.org/mirrors/npm/</span><br></pre></td></tr></table></figure><p>再次安装即能成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;nvm降级node安装sqlite3&quot;&gt;&lt;a href=&quot;#nvm降级node安装sqlite3&quot; class=&quot;headerlink&quot; title=&quot;nvm降级node安装sqlite3&quot;&gt;&lt;/a&gt;nvm降级node安装sqlite3&lt;/h2&gt;&lt;h3 id=&quot;n
      
    
    </summary>
    
    
    
      <category term="node" scheme="http://liubing.com/tags/node/"/>
    
      <category term="npm" scheme="http://liubing.com/tags/npm/"/>
    
      <category term="nvm" scheme="http://liubing.com/tags/nvm/"/>
    
  </entry>
  
  <entry>
    <title>Service Worker</title>
    <link href="http://liubing.com/2020/04/28/Service%20Worker/"/>
    <id>http://liubing.com/2020/04/28/Service%20Worker/</id>
    <published>2020-04-28T13:09:10.000Z</published>
    <updated>2021-07-16T02:27:02.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Service-Worker"><a href="#Service-Worker" class="headerlink" title="Service Worker"></a>Service Worker</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Service Worker本质上也是浏览器缓存资源用的，只不过他不仅仅是cache，也是通过worker的方式来进一步优化。</p><p>他基于h5的web worker，所以绝对不会阻碍当前js线程的执行，sw最重要的工作原理就是</p><ol><li><p>后台线程：独立于当前网页线程；</p></li><li><p>网络代理：在网页发起请求时代理，来缓存文件；</p></li></ol><h3 id="使用条件"><a href="#使用条件" class="headerlink" title="使用条件"></a>使用条件</h3><p>sw 是基于 HTTPS 的，因为service worker中涉及到请求拦截，所以必须使用HTTPS协议来保障安全。如果是本地调试的话，localhost是可以的。</p><h3 id="PWA"><a href="#PWA" class="headerlink" title="PWA"></a>PWA</h3><p>PWA是Progressive Web App的英文缩写， 翻译过来就是渐进式增强WEB应用。</p><h4 id="PWA中所包含的核心功能及特性"><a href="#PWA中所包含的核心功能及特性" class="headerlink" title="PWA中所包含的核心功能及特性"></a>PWA中所包含的核心功能及特性</h4><ol><li>Web App Manifest</li><li>Service Worker</li><li>Cache API缓存</li><li>Push &amp; Notification 推送与通知</li><li>Background Sync 后台同步</li><li>响应式设计</li></ol><p>在service worker忠，可以监听install、activate，message，fetch，sync，push等事件。</p><h3 id="WorkBox"><a href="#WorkBox" class="headerlink" title="WorkBox"></a>WorkBox</h3><p>在service worker中通过监听事件，然后编写对应逻辑，缓存文件都不是很容易。并且webpack build之后，js名称随时会变。因此chrome推出了workbox框架。</p><p><strong>workbox 是用于向web应用程序添加离线支持的JavaScript库。</strong></p><p>在wokbox对象中，包含很多模块，比如 workbox.routing模块，workbox.precaching模块，workbox.strategies模块，workbox.expiration模块等等，它们分别负责处理不同的逻辑。</p><ol><li>workbox缓存/预缓存</li><li>workbox路由</li><li>workbox插件</li></ol><p><a href="https://segmentfault.com/a/1190000019281388?utm_source=tag-newest">workbox的使用介绍</a></p><p>另外npm中也已经有这个包了<a href="https://link.jianshu.com/?t=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2Fweb-pwa">https://www.npmjs.com/package/web-pwa</a> ，可以玩玩。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Service-Worker&quot;&gt;&lt;a href=&quot;#Service-Worker&quot; class=&quot;headerlink&quot; title=&quot;Service Worker&quot;&gt;&lt;/a&gt;Service Worker&lt;/h2&gt;&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot;
      
    
    </summary>
    
    
    
      <category term="Service Worker" scheme="http://liubing.com/tags/Service-Worker/"/>
    
  </entry>
  
  <entry>
    <title>如何搭建一个简单的区块链</title>
    <link href="http://liubing.com/2020/04/20/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    <id>http://liubing.com/2020/04/20/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE/</id>
    <published>2020-04-20T01:35:10.000Z</published>
    <updated>2021-07-16T02:27:02.084Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何搭建一个简单的区块链"><a href="#如何搭建一个简单的区块链" class="headerlink" title="如何搭建一个简单的区块链"></a>如何搭建一个简单的区块链</h2><h3 id="bitcoin"><a href="#bitcoin" class="headerlink" title="bitcoin"></a>bitcoin</h3><p>Cypherpunk宣言</p><h3 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h3><p>八卦协议，流行病协议。</p><p>比特币使用的gossip protocol，Cassandra和redis Cluster都采用了gossip protocol以达到自动发现。以太坊使用的Kademlia。</p><h3 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h3><p>RSA非对称加密</p><p>ECC椭圆曲线加密</p><p>签名过程：私钥用于签名，公钥用于验证签名</p><p>交易过程：公钥用于加密，私钥用于解密</p><h3 id="共识机制"><a href="#共识机制" class="headerlink" title="共识机制"></a>共识机制</h3><p>PoW</p><p>PoS</p><p>DPos</p><h3 id="blockchain"><a href="#blockchain" class="headerlink" title="blockchain"></a>blockchain</h3><p>挖矿的本质是记账。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;如何搭建一个简单的区块链&quot;&gt;&lt;a href=&quot;#如何搭建一个简单的区块链&quot; class=&quot;headerlink&quot; title=&quot;如何搭建一个简单的区块链&quot;&gt;&lt;/a&gt;如何搭建一个简单的区块链&lt;/h2&gt;&lt;h3 id=&quot;bitcoin&quot;&gt;&lt;a href=&quot;#bitcoi
      
    
    </summary>
    
    
    
      <category term="blockchain" scheme="http://liubing.com/tags/blockchain/"/>
    
      <category term="ruby" scheme="http://liubing.com/tags/ruby/"/>
    
  </entry>
  
  <entry>
    <title>IPFS-Cluster客户端构建</title>
    <link href="http://liubing.com/2020/03/25/IPFS-Cluster%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9E%84%E5%BB%BA/"/>
    <id>http://liubing.com/2020/03/25/IPFS-Cluster%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9E%84%E5%BB%BA/</id>
    <published>2020-03-25T12:42:10.000Z</published>
    <updated>2021-07-16T02:27:02.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IPFS-Cluster客户端构建"><a href="#IPFS-Cluster客户端构建" class="headerlink" title="IPFS-Cluster客户端构建"></a>IPFS-Cluster客户端构建</h2><h2 id="安装windows构建插件"><a href="#安装windows构建插件" class="headerlink" title="安装windows构建插件"></a>安装windows构建插件</h2><p>需要使用管理员权限安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install –global –production windows-build-tools</span><br></pre></td></tr></table></figure><p>保证有python2.7的编译环境</p><h2 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git clone --depth 1 --single-branch https://github.com/caorushizi/oss-client.git</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入目录</span></span><br><span class="line">cd oss-client</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装依赖</span></span><br><span class="line">npx cross-env npm_config_electron_mirror=&quot;https://npm.taobao.org/mirrors/electron/&quot; npm_config_electron_custom_dir=&quot;7.1.9&quot; npm install</span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行</span></span><br><span class="line">npm start</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;IPFS-Cluster客户端构建&quot;&gt;&lt;a href=&quot;#IPFS-Cluster客户端构建&quot; class=&quot;headerlink&quot; title=&quot;IPFS-Cluster客户端构建&quot;&gt;&lt;/a&gt;IPFS-Cluster客户端构建&lt;/h2&gt;&lt;h2 id=&quot;安装win
      
    
    </summary>
    
    
    
      <category term="blockchain" scheme="http://liubing.com/tags/blockchain/"/>
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
      <category term="react" scheme="http://liubing.com/tags/react/"/>
    
      <category term="node" scheme="http://liubing.com/tags/node/"/>
    
      <category term="electron" scheme="http://liubing.com/tags/electron/"/>
    
  </entry>
  
  <entry>
    <title>IPFS-Cluster搭建(ubuntu)</title>
    <link href="http://liubing.com/2020/03/14/IPFS-Cluster%E6%90%AD%E5%BB%BA(ubuntu)/"/>
    <id>http://liubing.com/2020/03/14/IPFS-Cluster%E6%90%AD%E5%BB%BA(ubuntu)/</id>
    <published>2020-03-14T08:16:10.000Z</published>
    <updated>2021-07-16T02:27:02.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IPFS-Cluster搭建-ubuntu"><a href="#IPFS-Cluster搭建-ubuntu" class="headerlink" title="IPFS-Cluster搭建(ubuntu)"></a>IPFS-Cluster搭建(ubuntu)</h2><h2 id="Update-Linux-packages-and-dependencies"><a href="#Update-Linux-packages-and-dependencies" class="headerlink" title="Update Linux packages and dependencies:"></a>Update Linux packages and dependencies:</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y upgrade</span><br></pre></td></tr></table></figure><h2 id="Install-IPFS"><a href="#Install-IPFS" class="headerlink" title="Install IPFS"></a>Install IPFS</h2><p>准备好的go-ipfs资源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf go-ipfs_v0.4.23_linux-amd64.tar.gz</span><br><span class="line">cd go-ipfs</span><br><span class="line">sudo ./install.sh //安装文件自动mv /usr/local/bin</span><br><span class="line">ipfs init //ipfs初始化</span><br><span class="line">ipfs version</span><br></pre></td></tr></table></figure><h2 id="Creating-a-Private-network"><a href="#Creating-a-Private-network" class="headerlink" title="Creating a Private network"></a>Creating a Private network</h2><p>拷贝准备好的swarm.key到集群各个节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp swarm.key ~/.ipfs/swarm.key</span><br></pre></td></tr></table></figure><h2 id="Bootstrapping-IPFS-nodes"><a href="#Bootstrapping-IPFS-nodes" class="headerlink" title="Bootstrapping IPFS nodes"></a>Bootstrapping IPFS nodes</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipfs bootstrap rm --all</span><br><span class="line">ipfs bootstrap add /ip4/启动节点的ip地址/tcp/4001/ipfs/启动节点的id的hash</span><br></pre></td></tr></table></figure><p>也可以配置环境变量强制为private mode:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export LIBP2P_FORCE_PNET=1</span><br></pre></td></tr></table></figure><h2 id="Run-IPFS-daemon-as-a-service-in-the-background"><a href="#Run-IPFS-daemon-as-a-service-in-the-background" class="headerlink" title="Run IPFS daemon as a service in the background"></a>Run IPFS daemon as a service in the background</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo touch /etc/systemd/system/ipfs.service</span><br></pre></td></tr></table></figure><p>添加配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=IPFS Daemon</span><br><span class="line">After=syslog.target network.target remote-fs.target nss-lookup.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/local/bin/ipfs daemon --enable-namesys-pubsub</span><br><span class="line">User=$rootuser</span><br><span class="line">[Install] </span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>Apply新service。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable ipfs</span><br><span class="line">sudo systemctl start ipfs</span><br><span class="line">sudo systemctl status ipfs</span><br></pre></td></tr></table></figure><h2 id="Deploying-IPFS-Cluster"><a href="#Deploying-IPFS-Cluster" class="headerlink" title="Deploying IPFS-Cluster"></a>Deploying IPFS-Cluster</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf ipfs-cluster-service_v0.12.1_linux-amd64.tar.gz</span><br><span class="line">tar -zxf ipfs-cluster-ctl_v0.12.1_linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="Generate-and-set-up-CLUSTER-SECRET-variable"><a href="#Generate-and-set-up-CLUSTER-SECRET-variable" class="headerlink" title="Generate and set up CLUSTER_SECRET variable"></a>Generate and set up CLUSTER_SECRET variable</h2><p>在主节点，生成cluster-secret</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CLUSTER_SECRET=$(od -vN 32 -An -tx1 /dev/urandom | tr -d &#x27; \n&#x27;) </span><br><span class="line">echo $CLUSTER_SECRET</span><br></pre></td></tr></table></figure><p>把生成的cluster_secret设置入所有节点的.bashrc中再source</p><h2 id="Run-IPFS-Cluster-daemon-as-a-service"><a href="#Run-IPFS-Cluster-daemon-as-a-service" class="headerlink" title="Run IPFS-Cluster daemon as a service"></a>Run IPFS-Cluster daemon as a service</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo touch /etc/systemd/system/ipfs-cluster.service</span><br></pre></td></tr></table></figure><p>主节点添加配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=IPFS-Cluster Daemon</span><br><span class="line">Requires=ipfs</span><br><span class="line">After=syslog.target network.target remote-fs.target nss-lookup.target ipfs</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/home/$rootuser/ipfs-tools/ipfs-cluster-service/ipfs-cluster-service daemon</span><br><span class="line">User=$rootuser</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>子节点添加配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=IPFS-Cluster Daemon</span><br><span class="line">Requires=ipfs</span><br><span class="line">After=syslog.target network.target remote-fs.target nss-lookup.target ipfs</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/home/$rootuser/ipfs-tools/ipfs-cluster-service/ipfs-cluster-service daemon --bootstrap /ip4/38.91.120.173/tcp/9096/ipfs/12D3KooWSL6aP7UqkV8YruT99htjjdHQq4rHFvsRTrmdpSnt9cSL</span><br><span class="line">User=$rootuser</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>Apply新service。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable ipfs-cluster</span><br><span class="line">sudo systemctl start ipfs-cluster</span><br><span class="line">sudo systemctl status ipfs-cluster</span><br></pre></td></tr></table></figure><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;IPFS-Cluster搭建-ubuntu&quot;&gt;&lt;a href=&quot;#IPFS-Cluster搭建-ubuntu&quot; class=&quot;headerlink&quot; title=&quot;IPFS-Cluster搭建(ubuntu)&quot;&gt;&lt;/a&gt;IPFS-Cluster搭建(ubuntu)
      
    
    </summary>
    
    
    
      <category term="git" scheme="http://liubing.com/tags/git/"/>
    
      <category term="blockchain" scheme="http://liubing.com/tags/blockchain/"/>
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
  </entry>
  
  <entry>
    <title>IPFS-Cluster搭建</title>
    <link href="http://liubing.com/2020/03/14/IPFS-Cluster%E6%90%AD%E5%BB%BA/"/>
    <id>http://liubing.com/2020/03/14/IPFS-Cluster%E6%90%AD%E5%BB%BA/</id>
    <published>2020-03-14T08:16:10.000Z</published>
    <updated>2021-07-16T02:27:02.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IPFS-Cluster搭建"><a href="#IPFS-Cluster搭建" class="headerlink" title="IPFS-Cluster搭建"></a>IPFS-Cluster搭建</h2><p>私有网络集群允许IPFS节点只连接到拥有共享密钥的其他对等节点，网络中的节点不响应来自网络外节点的通信请求。IPFS-Cluster是一个独立的应用程序和一个CLI客户端 ，它跨一组IPFS守护进程分配、复制和跟踪pin。它使用基于Raft一致性算法来协调存储，将数据集合分布到参与的节点上。</p><p>目前在搭建分布式存储系统时，需要将一个peer上存储的文件同步备份到所有集群上的其他的peer上，或者对集群的节点管理，就需要IPFS-Cluster来实现。</p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="https://dist.ipfs.io/#go-ipfs">ipfs官网</a></p><p>进入官网选择合适的版本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://dist.ipfs.io/ipfs-cluster-ctl/v0.12.1/ipfs-cluster-ctl_v0.12.1_linux-amd64.tar.gz</span><br><span class="line">wget https://dist.ipfs.io/ipfs-cluster-service/v0.12.1/ipfs-cluster-service_v0.12.1_linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="安装ipfs-cluster-service"><a href="#安装ipfs-cluster-service" class="headerlink" title="安装ipfs-cluster-service"></a>安装ipfs-cluster-service</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf ipfs-cluster-service_v0.12.1_linux-amd64.tar.gz</span><br><span class="line">cd ipfs-cluster-service</span><br><span class="line">./ipfs-cluster-service init //初始化</span><br></pre></td></tr></table></figure><p>初始化之后会生成两个文件 </p><blockquote><p>.ipfs-cluster/service.json</p><blockquote><p>含有secret和监听端口，需要把secret配置到其他节点的service.json里，保证一样。</p></blockquote></blockquote><blockquote><p>.ipfs-cluster/identity.json</p><blockquote><p>含有cluster的节点id</p></blockquote></blockquote><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>主节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ipfs-cluster-service daemon &amp;</span><br></pre></td></tr></table></figure><p>其他节点启动–bootstrap添加主节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ipfs-cluster-service daemon --bootstrap /ip4/$主节点ip/tcp/9096/ipfs/$cluster id</span><br></pre></td></tr></table></figure><h2 id="安装ipfs-cluster-ctl"><a href="#安装ipfs-cluster-ctl" class="headerlink" title="安装ipfs-cluster-ctl"></a>安装ipfs-cluster-ctl</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf ipfs-cluster-ctl_v0.12.1_linux-amd64.tar.gz</span><br><span class="line">cd ipfs-cluster-ctl</span><br><span class="line">./ipfs-cluster-ctl peers ls</span><br></pre></td></tr></table></figure><h2 id="默认端口"><a href="#默认端口" class="headerlink" title="默认端口"></a>默认端口</h2><p>一定需要保证所有服务器的9094端口、9095端口、9096端口开放input的安全组。</p><ul><li>9094-HTTP API endpoint</li><li>9095-IPFS proxy endpoint</li><li>9096-Cluster swarm</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;IPFS-Cluster搭建&quot;&gt;&lt;a href=&quot;#IPFS-Cluster搭建&quot; class=&quot;headerlink&quot; title=&quot;IPFS-Cluster搭建&quot;&gt;&lt;/a&gt;IPFS-Cluster搭建&lt;/h2&gt;&lt;p&gt;私有网络集群允许IPFS节点只连接到拥有共享
      
    
    </summary>
    
    
    
      <category term="git" scheme="http://liubing.com/tags/git/"/>
    
      <category term="blockchain" scheme="http://liubing.com/tags/blockchain/"/>
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
  </entry>
  
  <entry>
    <title>IPFS搭建(windows节点)</title>
    <link href="http://liubing.com/2020/03/13/IPFS%E6%90%AD%E5%BB%BA(windows%E8%8A%82%E7%82%B9)/"/>
    <id>http://liubing.com/2020/03/13/IPFS%E6%90%AD%E5%BB%BA(windows%E8%8A%82%E7%82%B9)/</id>
    <published>2020-03-13T12:15:10.000Z</published>
    <updated>2021-07-16T02:27:02.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IPFS搭建-windows节点"><a href="#IPFS搭建-windows节点" class="headerlink" title="IPFS搭建(windows节点)"></a>IPFS搭建(windows节点)</h2><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="https://dist.ipfs.io/#go-ipfs">ipfs官网</a></p><p>进入官网选择合适的版本。<strong>Windows Binary</strong></p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>在下载好的binary文件夹里执行以下命令后，会在根目录生成一个.ipfs的文件夹存储节点数据。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipfs.exe init //初始化ipfs</span><br><span class="line">ipfs bootstrap rm -all //删除默认的bootstrap设置</span><br></pre></td></tr></table></figure><p>将集群中之前生成好的swarm.key文件拷贝进<strong>~.ipfs</strong>文件夹下</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>添加启动节点地址到当前节点的bootstrap列表中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs bootstrap add /ip4/启动节点的ip地址/tcp/4001/ipfs/启动节点的id的hash</span><br></pre></td></tr></table></figure><p>一定需要保证所有服务器的4001端口和5001端口开放input的安全组。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipfs daemon &amp; //启动，后台运行</span><br><span class="line">ipfs bootstrap list  //查看ipfs bootstrap列表</span><br></pre></td></tr></table></figure><p>在各个节点查看别的节点信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs swarm peers</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;IPFS搭建-windows节点&quot;&gt;&lt;a href=&quot;#IPFS搭建-windows节点&quot; class=&quot;headerlink&quot; title=&quot;IPFS搭建(windows节点)&quot;&gt;&lt;/a&gt;IPFS搭建(windows节点)&lt;/h2&gt;&lt;h2 id=&quot;下载&quot;&gt;&lt;a 
      
    
    </summary>
    
    
    
      <category term="git" scheme="http://liubing.com/tags/git/"/>
    
      <category term="blockchain" scheme="http://liubing.com/tags/blockchain/"/>
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
  </entry>
  
  <entry>
    <title>IPFS搭建</title>
    <link href="http://liubing.com/2020/03/06/IPFS%E6%90%AD%E5%BB%BA/"/>
    <id>http://liubing.com/2020/03/06/IPFS%E6%90%AD%E5%BB%BA/</id>
    <published>2020-03-06T06:30:11.000Z</published>
    <updated>2021-07-16T02:27:02.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IPFS搭建"><a href="#IPFS搭建" class="headerlink" title="IPFS搭建"></a>IPFS搭建</h2><h2 id="下载工具"><a href="#下载工具" class="headerlink" title="下载工具"></a>下载工具</h2><p><a href="https://dist.ipfs.io/#go-ipfs">ipfs官网</a></p><p>进入官网选择合适的版本。<strong>go-ipfs_v0.4.23_linux-amd64.tar.gz</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf  go-ipfs.tar.gz</span><br><span class="line">cd go-ipfs</span><br><span class="line">./install.sh //安装文件自动mv /usr/local/bin</span><br><span class="line">ipfs init //ipfs初始化</span><br></pre></td></tr></table></figure><p><a href="https://dl.google.com/go/go1.14.windows-amd64.msi">下载go</a></p><p>我下载的是windows版本。</p><h2 id="私有网络"><a href="#私有网络" class="headerlink" title="私有网络"></a>私有网络</h2><h3 id="清除缺省启动节点"><a href="#清除缺省启动节点" class="headerlink" title="清除缺省启动节点"></a>清除缺省启动节点</h3><p>默认会连接进ipfs的公链</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs bootstrap rm --all</span><br></pre></td></tr></table></figure><h3 id="生成秘钥"><a href="#生成秘钥" class="headerlink" title="生成秘钥"></a>生成秘钥</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Kubuxu/go-ipfs-swarm-key-gen.git //下载秘钥生成工具源码</span><br><span class="line">go build ipfs-swarm-key-gen/main.go //编译得到main.exe</span><br><span class="line">main.exe&gt;swarm.key //执行得到秘钥文件swarm.key</span><br></pre></td></tr></table></figure><h3 id="拷贝秘钥"><a href="#拷贝秘钥" class="headerlink" title="拷贝秘钥"></a>拷贝秘钥</h3><p>将生成的swarm.key文件拷贝进所有的节点服务器中<strong>~.ipfs</strong>文件夹下</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>选择一台稳定的公网ip地址为启动节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs id //查看该节点生成的hash</span><br></pre></td></tr></table></figure><p>添加该节点地址到所有节点的bootstrap列表中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs bootstrap add /ip4/启动节点的ip地址/tcp/4001/ipfs/启动节点的id的hash</span><br></pre></td></tr></table></figure><p>启动。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipfs daemon &amp; //启动，后台运行</span><br><span class="line">ipfs bootstrap list  //查看ipfs bootstrap列表</span><br></pre></td></tr></table></figure><p>在各个节点查看别的节点信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipfs swarm peers</span><br></pre></td></tr></table></figure><h2 id="上传下载"><a href="#上传下载" class="headerlink" title="上传下载"></a>上传下载</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipfs add xxx.png //上传到私链上，会返回hash码</span><br><span class="line">ipfs get hash码 // 下载</span><br></pre></td></tr></table></figure><h2 id="默认端口"><a href="#默认端口" class="headerlink" title="默认端口"></a>默认端口</h2><p>一定需要保证所有服务器的4001端口、5001端口、8080端口开放input的安全组。</p><ul><li>4001-与其他节点通信</li><li>5001-API server</li><li>8080-Gateway server</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;IPFS搭建&quot;&gt;&lt;a href=&quot;#IPFS搭建&quot; class=&quot;headerlink&quot; title=&quot;IPFS搭建&quot;&gt;&lt;/a&gt;IPFS搭建&lt;/h2&gt;&lt;h2 id=&quot;下载工具&quot;&gt;&lt;a href=&quot;#下载工具&quot; class=&quot;headerlink&quot; title=&quot;下
      
    
    </summary>
    
    
    
      <category term="git" scheme="http://liubing.com/tags/git/"/>
    
      <category term="blockchain" scheme="http://liubing.com/tags/blockchain/"/>
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
  </entry>
  
  <entry>
    <title>Peergos安装记</title>
    <link href="http://liubing.com/2020/03/02/Peergos%E5%AE%89%E8%A3%85/"/>
    <id>http://liubing.com/2020/03/02/Peergos%E5%AE%89%E8%A3%85/</id>
    <published>2020-03-02T06:30:11.000Z</published>
    <updated>2021-07-16T02:27:02.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Peergos安装记"><a href="#Peergos安装记" class="headerlink" title="Peergos安装记"></a>Peergos安装记</h2><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>作者在github里记录，为了跑tests，需要安装ant-optional这个插件，根据调查，ant-optional这个插件只有debian/ubuntu提供。因此准备一台ubuntu的机器。</p><h2 id="安装工具"><a href="#安装工具" class="headerlink" title="安装工具"></a>安装工具</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openjdk-11-jdk</span><br><span class="line">sudo apt-get install ant</span><br></pre></td></tr></table></figure><ul><li>ubuntu：Ubuntu 18.04.3 LTS</li><li>java：openjdk 11.0.6</li><li>ant：1.10.5</li></ul><h2 id="下载peergos"><a href="#下载peergos" class="headerlink" title="下载peergos"></a>下载peergos</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Peergos/Peergos.git</span><br><span class="line">git clone https://github.com/Peergos/web-ui.git</span><br></pre></td></tr></table></figure><h2 id="网络要求"><a href="#网络要求" class="headerlink" title="网络要求"></a>网络要求</h2><p>必须翻墙！！！</p><h2 id="build"><a href="#build" class="headerlink" title="build"></a>build</h2><p>根据github执行各种ant命令，启动后台就是下面的命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ant update_and_run</span><br></pre></td></tr></table></figure><p>考虑有两种方式运行web-ui。</p><ol><li>在ubuntu客户端通过ide运行整体系统。</li><li>前后端分离部署，前端通过命令ant ui来build静态资源文件，要修改vue的代码，在post/get等http请求中加入8000端口的后端url。通过nginx代理别的端口即可。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Peergos安装记&quot;&gt;&lt;a href=&quot;#Peergos安装记&quot; class=&quot;headerlink&quot; title=&quot;Peergos安装记&quot;&gt;&lt;/a&gt;Peergos安装记&lt;/h2&gt;&lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;head
      
    
    </summary>
    
    
    
      <category term="git" scheme="http://liubing.com/tags/git/"/>
    
      <category term="ipfs" scheme="http://liubing.com/tags/ipfs/"/>
    
      <category term="peergos" scheme="http://liubing.com/tags/peergos/"/>
    
  </entry>
  
  <entry>
    <title>gitignore更新后，删除未来不需要管控的程序</title>
    <link href="http://liubing.com/2019/07/22/gitignore%E6%9B%B4%E6%96%B0%E5%90%8E%EF%BC%8C%E5%88%A0%E9%99%A4%E6%9C%AA%E6%9D%A5%E4%B8%8D%E9%9C%80%E8%A6%81%E7%AE%A1%E6%8E%A7%E7%9A%84%E7%A8%8B%E5%BA%8F/"/>
    <id>http://liubing.com/2019/07/22/gitignore%E6%9B%B4%E6%96%B0%E5%90%8E%EF%BC%8C%E5%88%A0%E9%99%A4%E6%9C%AA%E6%9D%A5%E4%B8%8D%E9%9C%80%E8%A6%81%E7%AE%A1%E6%8E%A7%E7%9A%84%E7%A8%8B%E5%BA%8F/</id>
    <published>2019-07-22T06:30:11.000Z</published>
    <updated>2021-07-16T02:27:02.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="提交更新后的gitignore文件，删除本地缓存再提交"><a href="#提交更新后的gitignore文件，删除本地缓存再提交" class="headerlink" title="提交更新后的gitignore文件，删除本地缓存再提交"></a>提交更新后的gitignore文件，删除本地缓存再提交</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git rm -r --cached .</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;update .gitignore&quot;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;提交更新后的gitignore文件，删除本地缓存再提交&quot;&gt;&lt;a href=&quot;#提交更新后的gitignore文件，删除本地缓存再提交&quot; class=&quot;headerlink&quot; title=&quot;提交更新后的gitignore文件，删除本地缓存再提交&quot;&gt;&lt;/a&gt;提交更新后
      
    
    </summary>
    
    
    
      <category term="git" scheme="http://liubing.com/tags/git/"/>
    
      <category term="gitignore" scheme="http://liubing.com/tags/gitignore/"/>
    
  </entry>
  
  <entry>
    <title>hadoop+spark分布式环境搭建</title>
    <link href="http://liubing.com/2019/05/27/hadoop+spark%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://liubing.com/2019/05/27/hadoop+spark%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</id>
    <published>2019-05-27T10:50:11.000Z</published>
    <updated>2021-07-16T02:27:02.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hadoop整体框架"><a href="#Hadoop整体框架" class="headerlink" title="Hadoop整体框架"></a>Hadoop整体框架</h2><p>Hadoop由HDFS、MapReduce、HBase、Hive和ZooKeeper等成员组成，其中最基础最重要的两种组成元素为底层用于存储集群中所有存储节点文件的文件系统HDFS（Hadoop Distributed File System）和上层用来执行MapReduce程序的MapReduce引擎。</p><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>HDFS架构采用主从架构（master/slave）。一个典型的HDFS集群包含一个NameNode节点和多个DataNode节点。NameNode节点负责整个HDFS文件系统中的文件的元数据保管和管理，集群中通常只有一台机器上运行NameNode实例，DataNode节点保存文件中的数据，集群中的机器分别运行一个DataNode实例。在HDFS中，NameNode节点被称为名称节点，DataNode节点被称为数据节点。DataNode节点通过心跳机制与NameNode节点进行定时的通信。</p><h3 id="Map-Reduce"><a href="#Map-Reduce" class="headerlink" title="Map/Reduce"></a>Map/Reduce</h3><p>MapReduce是一种编程模型，用于大规模数据集的并行运算。Map（映射）和Reduce（化简），采用分而治之思想，先把任务分发到集群多个节点上，并行计算，然后再把计算结果合并，从而得到最终计算结果。多节点计算，所涉及的任务调度、负载均衡、容错处理等，都由MapReduce框架完成，不需要编程人员关心这些内容。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>准备了3台CentOS 6.10 64bit云服务器，1台做master NameNode主节点，2台做DataNode节点。</p><h3 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h3><p>在3台服务器上的/etc/hosts，追加以下配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.189 master worker0 namenode</span><br><span class="line">192.168.0.233 worker1 datanode1</span><br><span class="line">192.168.0.117 worker2 datanode2</span><br></pre></td></tr></table></figure><p>统一hosts文件，可以让主机通过host名字来识别彼此。<br><strong><label style="color:red">ip为内网ip，不能配公网ip，不然hadoop启动异常。9000端口未出现在监听中</label></strong></p><h3 id="ssh互信-免密登录"><a href="#ssh互信-免密登录" class="headerlink" title="ssh互信(免密登录)"></a>ssh互信(免密登录)</h3><p>在master节点执行以下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -P &#x27;&#x27; #生成公钥</span><br><span class="line">scp /root/.ssh/id_rsa.pub root@worker1:/root/.ssh/id_rsa.pub.master #从master节点拷贝id_rsa.pub到worker主机上,并且改名为id_rsa.pub.master</span><br><span class="line">scp /root/.ssh/id_rsa.pub root@worker2:/root/.ssh/id_rsa.pub.master</span><br><span class="line">cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>在node节点执行以下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /root/.ssh/id_rsa.pub.master &gt;&gt; /root/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><h2 id="下载工具"><a href="#下载工具" class="headerlink" title="下载工具"></a>下载工具</h2><ul><li>Java 1.8.0_211</li><li>Hadoop 3.1.2</li><li>Spark 2.4.3</li><li>Scala 2.11.12</li></ul><h3 id="Java安装"><a href="#Java安装" class="headerlink" title="Java安装"></a>Java安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u112-b15/jdk-8u112-linux-x64.rpm</span><br><span class="line">rpm ivh jdk-8u112-linux-x64.rpm</span><br></pre></td></tr></table></figure><h3 id="Hadoop安装"><a href="#Hadoop安装" class="headerlink" title="Hadoop安装"></a>Hadoop安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz</span><br><span class="line">tar -xvf hadoop-3.1.2.tar.gz</span><br><span class="line">mv hadoop-3.1.2 /opt</span><br></pre></td></tr></table></figure><h3 id="Spark安装"><a href="#Spark安装" class="headerlink" title="Spark安装"></a>Spark安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz</span><br><span class="line">tar -xvf spark-2.4.3-bin-hadoop2.7.tgz</span><br><span class="line">mv spark-2.4.3-bin-hadoop2.7 /opt</span><br></pre></td></tr></table></figure><h3 id="Scala安装"><a href="#Scala安装" class="headerlink" title="Scala安装"></a>Scala安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget -O &quot;scala-2.12.8.rpm&quot; &quot;https://downloads.lightbend.com/scala/2.12.8/scala-2.12.8.rpm&quot;</span><br><span class="line">rpm ivh scala-2.12.8.rpm</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置</p><h3 id="设定环境变量"><a href="#设定环境变量" class="headerlink" title="设定环境变量"></a>设定环境变量</h3><p>在/etc/profile中添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">java home</span></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_211-amd64/</span><br><span class="line"><span class="meta">#</span><span class="bash">scala home</span></span><br><span class="line">export SCALA_HOME=/usr/share/scala</span><br><span class="line"><span class="meta">#</span><span class="bash">hadoop enviroment</span></span><br><span class="line">export HADOOP_HOME=/opt/hadoop-3.1.2/</span><br><span class="line">export PATH=&quot;$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH&quot;</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line"><span class="meta">#</span><span class="bash">spark enviroment</span></span><br><span class="line">export SPARK_HOME=/opt/spark-2.4.3-bin-hadoop2.7/</span><br><span class="line">export PATH=&quot;$SPARK_HOME/bin:$PATH&quot;</span><br></pre></td></tr></table></figure><p>然后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h3><p>在<strong>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_211-amd64/</span><br></pre></td></tr></table></figure><p>在<strong>$HADOOP_HOME/etc/hadoop/workers</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">worker1</span><br><span class="line">worker2</span><br></pre></td></tr></table></figure><p>在<strong>$HADOOP_HOME/etc/hadoop/core-site.xml</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">         &lt;name&gt;io.file.buffer.size&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;131072&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/opt/hadoop-3.1.2/tmp&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>在<strong>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;file:/opt/hadoop-3.1.2/hdfs/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;file:/opt/hadoop-3.1.2/hdfs/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure><p>在<strong>$HADOOP_HOME/etc/hadoop/mapred-site.xml</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">          &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;master:10020&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">          &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;master:19888&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>在<strong>$HADOOP_HOME/etc/hadoop/yarn-site.xml</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">          &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">           &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;master:8032&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">          &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;master:8030&lt;/value&gt;</span><br><span class="line">      &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;master:8031&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;master:8033&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;master:8088&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br></pre></td></tr></table></figure><p>格式化<strong>namenode</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure><p><strong><label style="color:red">若多次格式化namenode，需先清空hadoop/tmp下文件，再格式化</label></strong></p><h3 id="配置Spark"><a href="#配置Spark" class="headerlink" title="配置Spark"></a>配置Spark</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure><p>在<strong>$SPARK_HOME/conf/spark-env.sh</strong>中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/usr/share/scala</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_211-amd64/</span><br><span class="line">export SPARK_MASTER_IP=master</span><br><span class="line">export SPARK_WORKER_MEMORY=1g</span><br><span class="line">export HADOOP_CONF_DIR=/opt/hadoop-3.1.2/etc/hadoop</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></figure><p>在<strong>$SPARK_HOME/conf/slaves</strong>文件中配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">worker1</span><br><span class="line">worker2</span><br></pre></td></tr></table></figure><h2 id="启动-关闭集群"><a href="#启动-关闭集群" class="headerlink" title="启动/关闭集群"></a>启动/关闭集群</h2><p>启动脚本start-cluster.sh如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo -e &quot;\033[31m ========Start The Cluster======== \033[0m&quot;</span><br><span class="line">echo -e &quot;\033[31m Starting Hadoop Now !!! \033[0m&quot;</span><br><span class="line">/opt/hadoop-3.1.2/sbin/start-all.sh</span><br><span class="line">echo -e &quot;\033[31m Starting Spark Now !!! \033[0m&quot;</span><br><span class="line">/opt/spark-2.4.3-bin-hadoop2.7/sbin/start-all.sh</span><br><span class="line">echo -e &quot;\033[31m The Result Of The Command \&quot;jps\&quot; :  \033[0m&quot;</span><br><span class="line">jps</span><br><span class="line">echo -e &quot;\033[31m ========END======== \033[0m&quot;</span><br></pre></td></tr></table></figure><p>关闭脚本stop-cluster.sh如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo -e &quot;\033[31m ===== Stoping The Cluster ====== \033[0m&quot;</span><br><span class="line">echo -e &quot;\033[31m Stoping Spark Now !!! \033[0m&quot;</span><br><span class="line">/opt/spark-2.4.3-bin-hadoop2.7/sbin/stop-all.sh</span><br><span class="line">echo -e &quot;\033[31m Stopting Hadoop Now !!! \033[0m&quot;</span><br><span class="line">/opt/hadoop-3.1.2/sbin/stop-all.sh</span><br><span class="line">echo -e &quot;\033[31m The Result Of The Command \&quot;jps\&quot; :  \033[0m&quot;</span><br><span class="line">jps</span><br><span class="line">echo -e &quot;\033[31m ======END======== \033[0m&quot;</span><br></pre></td></tr></table></figure><h3 id="JPS查看进程"><a href="#JPS查看进程" class="headerlink" title="JPS查看进程"></a>JPS查看进程</h3><p>master节点，jps查看进程信息如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">20069 Jps</span><br><span class="line">8118 NameNode</span><br><span class="line">9096 Worker</span><br><span class="line">8392 SecondaryNameNode</span><br><span class="line">9003 Master</span><br><span class="line">8655 ResourceManager</span><br></pre></td></tr></table></figure><p>node节点，jps查看进程信息如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">4210 DataNode</span><br><span class="line">7362 Jps</span><br><span class="line">4328 NodeManager</span><br></pre></td></tr></table></figure><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="could-only-be-written-to-0-of-the-1-minReplication-nodes"><a href="#could-only-be-written-to-0-of-the-1-minReplication-nodes" class="headerlink" title="could only be written to 0 of the 1 minReplication nodes."></a>could only be written to 0 of the 1 minReplication nodes.</h3><p>这个问题是由于使用hadoop namenode -format 格式化多次，导致spaceID不一致造成的，解决方法如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bash stop-cluster.sh</span><br><span class="line">rm -rf /tmp/*</span><br><span class="line">rm -rf /opt/hadoop-3.1.2/tmp/*</span><br><span class="line">hadoop namenode -format</span><br><span class="line">bash start-cluster.sh</span><br></pre></td></tr></table></figure><h3 id="ipc-Client-Retrying-connect-to-server-localhost-127-0-0-1"><a href="#ipc-Client-Retrying-connect-to-server-localhost-127-0-0-1" class="headerlink" title="ipc.Client: Retrying connect to server: localhost/127.0.0.1"></a>ipc.Client: Retrying connect to server: localhost/127.0.0.1</h3><p>配置logger为debugger模式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_ROOT_LOGGER=DEBUG,console</span><br></pre></td></tr></table></figure><p>查看具体报错信息</p><h3 id="Unable-to-load-native-hadoop-library"><a href="#Unable-to-load-native-hadoop-library" class="headerlink" title="Unable to load native-hadoop library"></a>Unable to load native-hadoop library</h3><p>去hadoop文件夹里找到libhadoop文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldd libhadoop.so</span><br></pre></td></tr></table></figure><h3 id="libc-so-6-version-GLIBC2-14-not-found"><a href="#libc-so-6-version-GLIBC2-14-not-found" class="headerlink" title="libc.so.6 version GLIBC2.14 not found"></a>libc.so.6 version GLIBC2.14 not found</h3><p>查看系统glibc版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strings /lib64/libc.so.6 |grep GLIBC_</span><br></pre></td></tr></table></figure><p>如果列表中系统支持的glibc的最高版本是GLIBC_2.12，则做升级</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz</span><br><span class="line">tar zxf glibc-2.14.tar.gz</span><br><span class="line">cd glibc-2.14 &amp;&amp; mkdri build</span><br><span class="line">cd build &amp;&amp; ../configure --prefix=/opt/glibc-2.14</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>安装成功之后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /lib64/libc.so.6</span><br><span class="line">ln -s /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果出问题，执行下面</span></span><br><span class="line">LD_PRELOAD=/opt/glibc-2.14/lib/libc-2.14.so ln -s /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6</span><br></pre></td></tr></table></figure><h3 id="There-are-0-datanode-s-running-and-no-node-s-are-excluded-in-this-operation"><a href="#There-are-0-datanode-s-running-and-no-node-s-are-excluded-in-this-operation" class="headerlink" title="There are 0 datanode(s) running and no node(s) are excluded in this operation"></a>There are 0 datanode(s) running and no node(s) are excluded in this operation</h3><p>这个错误是node没有正常设置。其中有可能涉及两个原因：</p><ul><li>主机在/etc/hosts里配置的是公网ip，改成内网ip。</li><li>hadoop在master和node中的配置保持一样。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Hadoop整体框架&quot;&gt;&lt;a href=&quot;#Hadoop整体框架&quot; class=&quot;headerlink&quot; title=&quot;Hadoop整体框架&quot;&gt;&lt;/a&gt;Hadoop整体框架&lt;/h2&gt;&lt;p&gt;Hadoop由HDFS、MapReduce、HBase、Hive和ZooKe
      
    
    </summary>
    
    
    
      <category term="hadoop" scheme="http://liubing.com/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://liubing.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>aws爬梯子</title>
    <link href="http://liubing.com/2019/01/17/aws%E7%88%AC%E6%A2%AF%E5%AD%90/"/>
    <id>http://liubing.com/2019/01/17/aws%E7%88%AC%E6%A2%AF%E5%AD%90/</id>
    <published>2019-01-17T06:30:11.000Z</published>
    <updated>2021-07-16T02:27:02.078Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ubuntu下亲测有效"><a href="#ubuntu下亲测有效" class="headerlink" title="ubuntu下亲测有效"></a>ubuntu下亲测有效</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</span><br><span class="line"></span><br><span class="line">chmod +x shadowsocks-all.sh</span><br><span class="line"></span><br><span class="line">./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;ubuntu下亲测有效&quot;&gt;&lt;a href=&quot;#ubuntu下亲测有效&quot; class=&quot;headerlink&quot; title=&quot;ubuntu下亲测有效&quot;&gt;&lt;/a&gt;ubuntu下亲测有效&lt;/h2&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;tabl
      
    
    </summary>
    
    
    
      <category term="aws" scheme="http://liubing.com/tags/aws/"/>
    
      <category term="梯子" scheme="http://liubing.com/tags/%E6%A2%AF%E5%AD%90/"/>
    
  </entry>
  
  <entry>
    <title>区块链挖矿</title>
    <link href="http://liubing.com/2018/10/20/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%96%E7%9F%BF/"/>
    <id>http://liubing.com/2018/10/20/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%96%E7%9F%BF/</id>
    <published>2018-10-20T08:30:11.000Z</published>
    <updated>2021-07-16T02:27:02.084Z</updated>
    
    <content type="html"><![CDATA[<h2 id="本地私链创世区块"><a href="#本地私链创世区块" class="headerlink" title="本地私链创世区块"></a>本地私链创世区块</h2><p>在当前文件夹下创建genesis.json文件</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;nonce&quot;</span>: <span class="string">&quot;0x0000000000000042&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span>: <span class="string">&quot;0x00&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;parentHash&quot;</span>: <span class="string">&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;extraData&quot;</span>: <span class="string">&quot;0x00&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;gasLimit&quot;</span>: <span class="string">&quot;0x80000000&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;difficulty&quot;</span>: <span class="string">&quot;0x01&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;mixhash&quot;</span>: <span class="string">&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;coinbase&quot;</span>: <span class="string">&quot;0x3333333333333333333333333333333333333333&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;alloc&quot;</span>: &#123;     &#125;,</span><br><span class="line">  <span class="attr">&quot;config&quot;</span>:&#123;</span><br><span class="line">      <span class="attr">&quot;chainId&quot;</span>:<span class="number">15</span>,</span><br><span class="line">      <span class="attr">&quot;homesteadBlock&quot;</span>:<span class="number">0</span>,</span><br><span class="line">      <span class="attr">&quot;eip155Block&quot;</span>:<span class="number">0</span>,</span><br><span class="line">      <span class="attr">&quot;eip158Block&quot;</span>:<span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">参数名|描述</span><br><span class="line">---:|--:</span><br><span class="line">chainId|指定了独立的区块链网络 ID。网络 ID 在连接到其他节点的时候会用到，以太坊公网的网络 ID 是 <span class="number">1</span>，为了不与公有链网络冲突，运行私有链节点的时候要指定自己的网络 ID。不同 ID 网络的节点无法相互连接。</span><br><span class="line">HomesteadBlock|当设置为<span class="number">0</span>表示使用Homestead发布该链。</span><br><span class="line">difficulty|设置设置当前区块的难度，越大挖矿就越难。</span><br><span class="line">alloc|用来预置账号以及账号的以太币数量。</span><br><span class="line">coinbase|矿工账号。</span><br><span class="line">timestamp|设置创世块的时间戳。</span><br><span class="line">parentHash|上一个区块的hash，创世块就为<span class="number">0</span>。</span><br><span class="line">extraData|附加信息。</span><br><span class="line">gasLimit|该值设置对GAS的消耗总量限制，用来限制区块能包含的交易信息总和。</span><br><span class="line">mixhash|与nonce配合用于挖矿，由上一个区块的一部分生成的hash。</span><br><span class="line">nonce|nonce就是一个<span class="number">64</span>位随机数，用于挖矿。</span><br><span class="line"></span><br><span class="line">## 初始化创始区块</span><br><span class="line"></span><br><span class="line">### geth</span><br><span class="line">geth是以太坊的客户端程序。全称是Go-ethereum，是用go语言编写的。目前比较常用。</span><br><span class="line">[官网下载地址](https:<span class="comment">//www.ethereum.org/cli)</span></span><br><span class="line"></span><br><span class="line">### 初始化genesis.json文件</span><br><span class="line">```shell</span><br><span class="line">geth --datadir <span class="string">&quot;D:\github\blockchain-learn\tmpPrivate&quot;</span> init <span class="string">&quot;D:\github\blockchain-learn\tmpPrivate\genesis.json&quot;</span></span><br></pre></td></tr></table></figure><h2 id="创建私链"><a href="#创建私链" class="headerlink" title="创建私链"></a>创建私链</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">geth --datadir &quot;D:\github\blockchain-learn\tmpPrivate&quot; --nodiscover console 2&gt;&gt;geth.log</span><br><span class="line">personal.neweAccount(&quot;liubing&quot;)</span><br><span class="line">eth.accounts</span><br></pre></td></tr></table></figure><h2 id="挖矿"><a href="#挖矿" class="headerlink" title="挖矿"></a>挖矿</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">miner.start()</span><br><span class="line">eth.getBalance(eth.accounts[0])</span><br><span class="line">eth.blockNumber</span><br><span class="line">miner.stop()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;本地私链创世区块&quot;&gt;&lt;a href=&quot;#本地私链创世区块&quot; class=&quot;headerlink&quot; title=&quot;本地私链创世区块&quot;&gt;&lt;/a&gt;本地私链创世区块&lt;/h2&gt;&lt;p&gt;在当前文件夹下创建genesis.json文件&lt;/p&gt;
&lt;figure class=&quot;hig
      
    
    </summary>
    
    
    
      <category term="区块链" scheme="http://liubing.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="智能合约" scheme="http://liubing.com/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>区块链入门</title>
    <link href="http://liubing.com/2018/10/13/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8/"/>
    <id>http://liubing.com/2018/10/13/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%A5%E9%97%A8/</id>
    <published>2018-10-13T07:19:11.000Z</published>
    <updated>2021-07-16T02:27:02.084Z</updated>
    
    <content type="html"><![CDATA[<h2 id="区块链的特点"><a href="#区块链的特点" class="headerlink" title="区块链的特点"></a>区块链的特点</h2><ul><li>匿名</li><li>不可篡改和加密安全性</li><li>无须信任系统</li><li>分布式去中心化</li><li>交易透明</li></ul><h2 id="以太坊"><a href="#以太坊" class="headerlink" title="以太坊"></a>以太坊</h2><p>以太坊=区块链技术+智能合约</p><h2 id="智能合约"><a href="#智能合约" class="headerlink" title="智能合约"></a>智能合约</h2><p>智能合约可以是一个众筹合约，也可以是一个数学公式，或者是一个完全的随机数。</p><h3 id="智能合约实践"><a href="#智能合约实践" class="headerlink" title="智能合约实践"></a>智能合约实践</h3><h4 id="browser-solidity"><a href="#browser-solidity" class="headerlink" title="browser-solidity"></a>browser-solidity</h4><p><a href="https://ethereum.github.io/browser-solidity/#version=soljson-v0.4.9+commit.364da425.js">官网</a></p><h4 id="最简单的智能合约"><a href="#最简单的智能合约" class="headerlink" title="最简单的智能合约"></a>最简单的智能合约</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pragma solidity <span class="number">0.4</span><span class="number">.9</span>;</span><br><span class="line">contract DemoTypes &#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">uint a</span>) <span class="title">returns</span> (<span class="params">uint b</span>) </span>&#123;</span><br><span class="line">    uint result = a * <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>※目前使用的solidity版本是0.4.9<br><img src="http://obksgg9lx.bkt.clouddn.com/solidity-simple.png" alt="solidity-simple"></p><ol><li>点击create会将智能合约部署到区块链的网络上（内存上）</li><li>trasaction/execution cost代表create一个智能合约所消耗的成本，单位为gas。gas和ether币有一个兑换关系。</li><li>合约名字DemoTypes注册在了一个地址上，则说明该合约已被挖矿出来了。</li><li>输入100，点击f按钮，进行计算得800。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;区块链的特点&quot;&gt;&lt;a href=&quot;#区块链的特点&quot; class=&quot;headerlink&quot; title=&quot;区块链的特点&quot;&gt;&lt;/a&gt;区块链的特点&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;匿名&lt;/li&gt;
&lt;li&gt;不可篡改和加密安全性&lt;/li&gt;
&lt;li&gt;无须信任系统&lt;/li&gt;
&lt;li&gt;
      
    
    </summary>
    
    
    
      <category term="区块链" scheme="http://liubing.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="智能合约" scheme="http://liubing.com/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>构建python的多并发分布式系统</title>
    <link href="http://liubing.com/2018/06/27/%E6%9E%84%E5%BB%BApython%E7%9A%84%E5%A4%9A%E5%B9%B6%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    <id>http://liubing.com/2018/06/27/%E6%9E%84%E5%BB%BApython%E7%9A%84%E5%A4%9A%E5%B9%B6%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</id>
    <published>2018-06-27T02:29:46.000Z</published>
    <updated>2021-07-16T02:27:02.084Z</updated>
    
    <content type="html"><![CDATA[<h3 id="IO密集型的应对"><a href="#IO密集型的应对" class="headerlink" title="IO密集型的应对"></a>IO密集型的应对</h3><p>我们一直致力于采用flask（纯python编写的轻量级web框架）来构建快速开发的微服务应用，并将其应用于工作中项目中。<br>部署时，采用Gunicorn或者uWSGI作为http服务器，因其支持gevent和monkey_patch，立刻就能使同步的web框架获得数倍的性能提升。（*注 gevent对标准I/O函数做了monkey_patch，把它们变成了异步。并且gevent有greenlet对象能够被用于并发执行。）   </p><h3 id="CPU密集型的应对"><a href="#CPU密集型的应对" class="headerlink" title="CPU密集型的应对"></a>CPU密集型的应对</h3><p>然而真实的应用场景下，无论是CPU密集型运算或者是庞大的I/O操作，都会对服务器主机造成相当大的负担。<br>比如在我们当前的项目里，有一个很重要的模块需要做算法进行复杂的数学运算。在运算过程中服务器会跑满cpu，并且运算时间很长，大概70秒才可以做完一次处理。如果单纯的将http服务器的worker提升至服务器cpu数量，多并发的request数量也会及其有限，并且压上去的request越多，导致阻塞的时间就会越长，不仅用户体验不好，而且超过了nginx配置的最大连接时间，也会报错。（<em>注 如果架构中使用了nginx做反向代理的话）<br>那么我们将问题梳理一下。在CPU密集型应用中，如何提升服务器性能？（</em>注 IO密集型的问题，已经采用了Gunicorn或者uWSGI的http服务器帮我们单纯应对了。）<br>CPU密集型的问题，我们采用了celery，redis（也可以采用rabbitmq)，及multiprocessing来解决。<br>首先我们将CPU密集型的运算从同步处理中拉出来，做成单个的任务模块，扔进消息队列里，然后异步返回给客户端。<br>其次将服务器主机集群都注册成统一的消息中间件和任务结果存储地址。这样在运行过程中可以根据任务的多少，动态的可插拔式的添加分布式系统的节点，或者删除节点。<br>最后对于单节点应用，我们采用了multiporcessing做分核处理，比如单主机单进程一个CPU跑满大概需要70秒，分成4核做并行处理，则会大概花18秒左右跑出结果。<br>这样，基于微服务的可扩展的多并发分布式系统就构建完成了。其他开发语言的拆分过程思想同理。    </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;IO密集型的应对&quot;&gt;&lt;a href=&quot;#IO密集型的应对&quot; class=&quot;headerlink&quot; title=&quot;IO密集型的应对&quot;&gt;&lt;/a&gt;IO密集型的应对&lt;/h3&gt;&lt;p&gt;我们一直致力于采用flask（纯python编写的轻量级web框架）来构建快速开发的微服务应
      
    
    </summary>
    
    
    
      <category term="python" scheme="http://liubing.com/tags/python/"/>
    
      <category term="celery" scheme="http://liubing.com/tags/celery/"/>
    
      <category term="多并发" scheme="http://liubing.com/tags/%E5%A4%9A%E5%B9%B6%E5%8F%91/"/>
    
      <category term="multiprocessing" scheme="http://liubing.com/tags/multiprocessing/"/>
    
  </entry>
  
  <entry>
    <title>npm Error! ENOENT no such file or directory .dezalgo.DELETE&#39;</title>
    <link href="http://liubing.com/2018/06/11/npm%20Error!%20ENOENT%20no%20such%20file%20or%20directory%20.dezalgo.DELETE&#39;/"/>
    <id>http://liubing.com/2018/06/11/npm%20Error!%20ENOENT%20no%20such%20file%20or%20directory%20.dezalgo.DELETE&#39;/</id>
    <published>2018-06-11T03:04:46.000Z</published>
    <updated>2021-07-16T02:27:02.082Z</updated>
    
    <content type="html"><![CDATA[<h2 id="这是npm5-6-0的bug"><a href="#这是npm5-6-0的bug" class="headerlink" title="这是npm5.6.0的bug"></a>这是npm5.6.0的bug</h2><p>更新升级</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g npm@4.6.1</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://stackoverflow.com/questions/48351466/npm-error-enoent-no-such-file-or-directory-dezalgo-delete">stackoverflow的回答</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;这是npm5-6-0的bug&quot;&gt;&lt;a href=&quot;#这是npm5-6-0的bug&quot; class=&quot;headerlink&quot; title=&quot;这是npm5.6.0的bug&quot;&gt;&lt;/a&gt;这是npm5.6.0的bug&lt;/h2&gt;&lt;p&gt;更新升级&lt;/p&gt;
&lt;figure class
      
    
    </summary>
    
    
    
      <category term="npm" scheme="http://liubing.com/tags/npm/"/>
    
      <category term="dezalgo" scheme="http://liubing.com/tags/dezalgo/"/>
    
  </entry>
  
  <entry>
    <title>multiprocessing的并行方式</title>
    <link href="http://liubing.com/2018/05/24/multiprocessing%E7%9A%84%E5%B9%B6%E8%A1%8C%E6%96%B9%E5%BC%8F/"/>
    <id>http://liubing.com/2018/05/24/multiprocessing%E7%9A%84%E5%B9%B6%E8%A1%8C%E6%96%B9%E5%BC%8F/</id>
    <published>2018-05-24T02:35:11.000Z</published>
    <updated>2021-07-16T02:27:02.081Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>multiprocessing模块让你使用基于进程和基于线程的并行处理，在队列上共享任务，以及在进程间共享数据。它主要是集中于单机多核的并行（对多机并行来说，有更好的选择）。<br>一个很普遍的用法就是针对CPU密集型的问题，在一个进程集上并行化一个任务。</p><h2 id="并行运算"><a href="#并行运算" class="headerlink" title="并行运算"></a>并行运算</h2><ul><li>避免共享状态会让并行运算变得简单很多。</li><li>每一个进程需要和其他进程来通信的话，那么通信开销将减慢整体的性能。</li></ul><p>Python中的线程是OS原生的，它们被全局解释锁(GIL)所束缚，所以同一时刻只有一个线程可以被交互。因此Python都会并行一定数量的进程，每一个进程都有私有的内存空间与GIL。如果需要共享状态，就需要增加一些通信的开销。</p><h2 id="multiprocessing模块"><a href="#multiprocessing模块" class="headerlink" title="multiprocessing模块"></a>multiprocessing模块</h2><ul><li>用进程或者池对象来并行化一个CPU密集型任务。</li><li>用dummy模块在线程池中并行化一个I/O密集型任务。</li><li>由队列来共享任务。</li><li>在并行工作者之间共享状态，包括字节、原生数据类型、字典和列表。</li></ul><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>一个当前进程的forked拷贝，创建了一个新的进程标识符，在OS中以一个独立的子进程运行。</p><h3 id="池"><a href="#池" class="headerlink" title="池"></a>池</h3><p>包装了进程和线程。在工作者线程池中共享了工作块并返回聚合后的结果。</p><h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><p>一个FIFP（先进先出）的队列允许多个生产者和消费者。</p><h3 id="管理者"><a href="#管理者" class="headerlink" title="管理者"></a>管理者</h3><p>一个单向或双向的在两个进程间的通信渠道。</p><h3 id="ctypes"><a href="#ctypes" class="headerlink" title="ctypes"></a>ctypes</h3><p>允许在进程派生后，在父子进程间共享原生数据类型（整数型、浮点型和字节型）</p><h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>锁和信号量在进程间同步。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">from</span> multiprocessing.pool <span class="keyword">import</span> ThreadPool, Pool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">slp</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;received: %s&quot;</span> % (a)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">pool = Pool(processes=<span class="number">4</span>)</span><br><span class="line">start_time = time.clock()</span><br><span class="line">d_l = []</span><br><span class="line">p_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">4</span>):</span><br><span class="line">async_result = pool.apply_async(slp, [i,])</span><br><span class="line">p_list.append(async_result)</span><br><span class="line"><span class="comment"># d_l.append(async_result.get())</span></span><br><span class="line">pool.close()</span><br><span class="line">pool.join()</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> p_list:</span><br><span class="line">d_l.append(p.get())</span><br><span class="line"><span class="comment"># p_list = []</span></span><br><span class="line"><span class="comment"># for i in range(0, 4):</span></span><br><span class="line"><span class="comment">#     p = Process(target=slp)</span></span><br><span class="line"><span class="comment">#     p.start()</span></span><br><span class="line"><span class="comment">#     p_list.append(p)</span></span><br><span class="line"><span class="comment"># for p in p_list:</span></span><br><span class="line"><span class="comment">#     p.join()</span></span><br><span class="line">end_time = time.clock()</span><br><span class="line">duration = <span class="built_in">round</span>(end_time - start_time, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;time: %s&#x27;</span> % duration</span><br><span class="line"><span class="built_in">print</span> d_l</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">received: 0</span><br><span class="line">received: 1</span><br><span class="line">received: 2</span><br><span class="line">received: 3</span><br><span class="line">time: 2.12</span><br><span class="line">[0, 1, 2, 3]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;multiprocessing模块让你使用基于进程和基于线程的并行处理，在队列上共享任务，以及在进程间共享数据。它主要是集中于单机多核的并行
      
    
    </summary>
    
    
    
      <category term="multiprocessing" scheme="http://liubing.com/tags/multiprocessing/"/>
    
      <category term="并行" scheme="http://liubing.com/tags/%E5%B9%B6%E8%A1%8C/"/>
    
  </entry>
  
</feed>
